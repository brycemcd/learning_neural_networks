{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import datetime\n",
    "np.random.seed(81)\n",
    "\n",
    "import h5py\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten, Conv2D, MaxPooling2D # new!\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# conv 1\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(240, 320, 1)))\n",
    "#model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name=\"doop\"))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "# conv 2\n",
    "model.add(Conv2D(128, kernel_size=(8, 8), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "# Fully Connected\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "json_string = model.to_json()\n",
    "\n",
    "model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Pretend I just pulled this string off a queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare_football_data_for_keras import DataPreperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Inputs 8000\n",
      "Train labels [ 4000.  4000.]\n",
      "Test Inputs 2000\n",
      "Test labels [ 1000.  1000.]\n",
      "Validation Inputs 0\n",
      "Validation labels 0\n"
     ]
    }
   ],
   "source": [
    "dp = DataPreperator()\n",
    "train_x, train_y, test_x, test_y = dp.load_data()\n",
    "dp.print_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Inputs 8000\n",
      "Train labels [ 4000.  4000.]\n",
      "Test Inputs 1000\n",
      "Test labels [ 496.  504.]\n",
      "Validation Inputs 1000\n",
      "Validation labels [ 504.  496.]\n"
     ]
    }
   ],
   "source": [
    "dp.create_validation_split()\n",
    "dp.print_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y, test_x, test_y, val_x, val_y) = dp.get_data_sets()\n",
    "train_x = train_x[:10]\n",
    "train_y = train_y[:10]\n",
    "val_x = val_x[:10]\n",
    "val_y = val_y[:10]\n",
    "test_x = test_x[:10]\n",
    "test_y = test_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use some sort of grid search to optimize this\n",
    "sgd = keras.optimizers.SGD(lr=1e-3, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-11-24T14:20:35.966547'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time_start = datetime.datetime.now().isoformat()\n",
    "training_time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/3\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.7040 - acc: 0.4000 - val_loss: 0.6962 - val_acc: 0.4000\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.6915 - acc: 0.6000 - val_loss: 0.6987 - val_acc: 0.4000\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.6757 - acc: 1.0000 - val_loss: 0.7018 - val_acc: 0.4000\n"
     ]
    }
   ],
   "source": [
    "training_hx = model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "          batch_size=128, #220\n",
    "          epochs=3, #FIXME: turn this back into 10\n",
    "          verbose=1,\n",
    "          validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-11-24T14:22:21.612292'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time_end = datetime.datetime.now().isoformat()\n",
    "training_time_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "10/10 [==============================] - 7s 689ms/step\n"
     ]
    }
   ],
   "source": [
    "training_eval = model.evaluate(test_x, test_y, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.60000002384185791, 'loss': 0.67571365833282471}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics = dict(zip(model.metrics_names, training_eval))\n",
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** is a merge function\n",
    "evaluation_metrics = {**evaluation_metrics,\n",
    "                      **training_hx.params,\n",
    "                      **{'history' : training_hx.history},\n",
    "                      **{'training_time_start' : training_time_start, 'training_time_end' : training_time_end}\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.60000002384185791,\n",
       " 'batch_size': 128,\n",
       " 'do_validation': True,\n",
       " 'epochs': 3,\n",
       " 'history': {'acc': [0.40000000596046448, 0.60000002384185791, 1.0],\n",
       "  'loss': [0.70398461818695068, 0.69150745868682861, 0.67569488286972046],\n",
       "  'val_acc': [0.40000000596046448, 0.40000000596046448, 0.40000000596046448],\n",
       "  'val_loss': [0.69616776704788208, 0.69872903823852539, 0.70177972316741943]},\n",
       " 'loss': 0.67571365833282471,\n",
       " 'metrics': ['loss', 'acc', 'val_loss', 'val_acc'],\n",
       " 'samples': 10,\n",
       " 'steps': None,\n",
       " 'training_time_end': '2017-11-24T14:22:21.612292',\n",
       " 'training_time_start': '2017-11-24T14:20:35.966547',\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.40000000596046448, 0.60000002384185791, 1.0],\n",
       " 'loss': [0.70398461818695068, 0.69150745868682861, 0.67569488286972046],\n",
       " 'val_acc': [0.40000000596046448, 0.40000000596046448, 0.40000000596046448],\n",
       " 'val_loss': [0.69616776704788208, 0.69872903823852539, 0.70177972316741943]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_hx.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.60000002384185791,\n",
       " 'batch_size': 128,\n",
       " 'do_validation': True,\n",
       " 'epochs': 3,\n",
       " 'history': {'acc': [0.40000000596046448, 0.60000002384185791, 1.0],\n",
       "  'loss': [0.70398461818695068, 0.69150745868682861, 0.67569488286972046],\n",
       "  'val_acc': [0.40000000596046448, 0.40000000596046448, 0.40000000596046448],\n",
       "  'val_loss': [0.69616776704788208, 0.69872903823852539, 0.70177972316741943]},\n",
       " 'loss': 'categorical_crossentropy',\n",
       " 'metrics': ['loss', 'acc', 'val_loss', 'val_acc'],\n",
       " 'optimizer_class': 'SGD',\n",
       " 'optimizer_config': {'decay': 0.0,\n",
       "  'lr': 0.0010000000474974513,\n",
       "  'momentum': 0.0,\n",
       "  'nesterov': True},\n",
       " 'samples': 10,\n",
       " 'steps': None,\n",
       " 'training_time_end': '2017-11-24T14:22:21.612292',\n",
       " 'training_time_start': '2017-11-24T14:20:35.966547',\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics = {**evaluation_metrics,\n",
    "**{\n",
    "    \"loss\" : model.loss,\n",
    "    \"optimizer_config\" : model.optimizer.get_config(),\n",
    "    \"optimizer_class\" : str(model.optimizer.__class__.__name__),\n",
    "}}\n",
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics = {**evaluation_metrics, **json.loads(model.to_json())}\n",
    "# TODO version the data somehow and include the version of the training/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"loss\": \"categorical_crossentropy\",\n",
      "  \"acc\": 0.6000000238418579,\n",
      "  \"batch_size\": 128,\n",
      "  \"epochs\": 3,\n",
      "  \"steps\": null,\n",
      "  \"samples\": 10,\n",
      "  \"verbose\": 1,\n",
      "  \"do_validation\": true,\n",
      "  \"metrics\": [\n",
      "    \"loss\",\n",
      "    \"acc\",\n",
      "    \"val_loss\",\n",
      "    \"val_acc\"\n",
      "  ],\n",
      "  \"history\": {\n",
      "    \"val_loss\": [\n",
      "      0.6961677670478821,\n",
      "      0.6987290382385254,\n",
      "      0.7017797231674194\n",
      "    ],\n",
      "    \"val_acc\": [\n",
      "      0.4000000059604645,\n",
      "      0.4000000059604645,\n",
      "      0.4000000059604645\n",
      "    ],\n",
      "    \"loss\": [\n",
      "      0.7039846181869507,\n",
      "      0.6915074586868286,\n",
      "      0.6756948828697205\n",
      "    ],\n",
      "    \"acc\": [\n",
      "      0.4000000059604645,\n",
      "      0.6000000238418579,\n",
      "      1.0\n",
      "    ]\n",
      "  },\n",
      "  \"training_time_start\": \"2017-11-24T14:20:35.966547\",\n",
      "  \"training_time_end\": \"2017-11-24T14:22:21.612292\",\n",
      "  \"optimizer_config\": {\n",
      "    \"lr\": 0.0010000000474974513,\n",
      "    \"momentum\": 0.0,\n",
      "    \"decay\": 0.0,\n",
      "    \"nesterov\": true\n",
      "  },\n",
      "  \"optimizer_class\": \"SGD\",\n",
      "  \"class_name\": \"Sequential\",\n",
      "  \"config\": [\n",
      "    {\n",
      "      \"class_name\": \"Conv2D\",\n",
      "      \"config\": {\n",
      "        \"name\": \"conv2d_1\",\n",
      "        \"trainable\": true,\n",
      "        \"batch_input_shape\": [\n",
      "          null,\n",
      "          240,\n",
      "          320,\n",
      "          1\n",
      "        ],\n",
      "        \"dtype\": \"float32\",\n",
      "        \"filters\": 128,\n",
      "        \"kernel_size\": [\n",
      "          3,\n",
      "          3\n",
      "        ],\n",
      "        \"strides\": [\n",
      "          1,\n",
      "          1\n",
      "        ],\n",
      "        \"padding\": \"same\",\n",
      "        \"data_format\": \"channels_last\",\n",
      "        \"dilation_rate\": [\n",
      "          1,\n",
      "          1\n",
      "        ],\n",
      "        \"activation\": \"relu\",\n",
      "        \"use_bias\": true,\n",
      "        \"kernel_initializer\": {\n",
      "          \"class_name\": \"VarianceScaling\",\n",
      "          \"config\": {\n",
      "            \"scale\": 1.0,\n",
      "            \"mode\": \"fan_avg\",\n",
      "            \"distribution\": \"uniform\",\n",
      "            \"seed\": null\n",
      "          }\n",
      "        },\n",
      "        \"bias_initializer\": {\n",
      "          \"class_name\": \"Zeros\",\n",
      "          \"config\": {}\n",
      "        },\n",
      "        \"kernel_regularizer\": null,\n",
      "        \"bias_regularizer\": null,\n",
      "        \"activity_regularizer\": null,\n",
      "        \"kernel_constraint\": null,\n",
      "        \"bias_constraint\": null\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"class_name\": \"MaxPooling2D\",\n",
      "      \"config\": {\n",
      "        \"name\": \"doop\",\n",
      "        \"trainable\": true,\n",
      "        \"pool_size\": [\n",
      "          2,\n",
      "          2\n",
      "        ],\n",
      "        \"padding\": \"same\",\n",
      "        \"strides\": [\n",
      "          2,\n",
      "          2\n",
      "        ],\n",
      "        \"data_format\": \"channels_last\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"class_name\": \"Dropout\",\n",
      "      \"config\": {\n",
      "        \"name\": \"dropout_1\",\n",
      "        \"trainable\": true,\n",
      "        \"rate\": 0.1,\n",
      "        \"noise_shape\": null,\n",
      "        \"seed\": null\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"class_name\": \"Conv2D\",\n",
      "      \"config\": {\n",
      "        \"name\": \"conv2d_2\",\n",
      "        \"trainable\": true,\n",
      "        \"filters\": 128,\n",
      "        \"kernel_size\": [\n",
      "          8,\n",
      "          8\n",
      "        ],\n",
      "        \"strides\": [\n",
      "          1,\n",
      "          1\n",
      "        ],\n",
      "        \"padding\": \"same\",\n",
      "        \"data_format\": \"channels_last\",\n",
      "        \"dilation_rate\": [\n",
      "          1,\n",
      "          1\n",
      "        ],\n",
      "        \"activation\": \"relu\",\n",
      "        \"use_bias\": true,\n",
      "        \"kernel_initializer\": {\n",
      "          \"class_name\": \"VarianceScaling\",\n",
      "          \"config\": {\n",
      "            \"scale\": 1.0,\n",
      "            \"mode\": \"fan_avg\",\n",
      "            \"distribution\": \"uniform\",\n",
      "            \"seed\": null\n",
      "          }\n",
      "        },\n",
      "        \"bias_initializer\": {\n",
      "          \"class_name\": \"Zeros\",\n",
      "          \"config\": {}\n",
      "        },\n",
      "        \"kernel_regularizer\": null,\n",
      "        \"bias_regularizer\": null,\n",
      "        \"activity_regularizer\": null,\n",
      "        \"kernel_constraint\": null,\n",
      "        \"bias_constraint\": null\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"class_name\": \"MaxPooling2D\",\n",
      "      \"config\": {\n",
      "        \"name\": \"max_pooling2d_1\",\n",
      "        \"trainable\": true,\n",
      "        \"pool_size\": [\n",
      "          5,\n",
      "          5\n",
      "        ],\n",
      "        \"padding\": \"same\",\n",
      "        \"strides\": [\n",
      "          5,\n",
      "          5\n",
      "        ],\n",
      "        \"data_format\": \"channels_last\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"class_name\": \"Dropout\",\n",
      "      \"config\": {\n",
      "        \"name\": \"dropout_2\",\n",
      "        \"trainable\": true,\n",
      "        \"rate\": 0.1,\n",
      "        \"noise_shape\": null,\n",
      "        \"seed\": null\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"class_name\": \"Flatten\",\n",
      "      \"config\": {\n",
      "        \"name\": \"flatten_1\",\n",
      "        \"trainable\": true\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"class_name\": \"Dense\",\n",
      "      \"config\": {\n",
      "        \"name\": \"dense_1\",\n",
      "        \"trainable\": true,\n",
      "        \"units\": 1024,\n",
      "        \"activation\": \"relu\",\n",
      "        \"use_bias\": true,\n",
      "        \"kernel_initializer\": {\n",
      "          \"class_name\": \"VarianceScaling\",\n",
      "          \"config\": {\n",
      "            \"scale\": 1.0,\n",
      "            \"mode\": \"fan_avg\",\n",
      "            \"distribution\": \"uniform\",\n",
      "            \"seed\": null\n",
      "          }\n",
      "        },\n",
      "        \"bias_initializer\": {\n",
      "          \"class_name\": \"Zeros\",\n",
      "          \"config\": {}\n",
      "        },\n",
      "        \"kernel_regularizer\": null,\n",
      "        \"bias_regularizer\": null,\n",
      "        \"activity_regularizer\": null,\n",
      "        \"kernel_constraint\": null,\n",
      "        \"bias_constraint\": null\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"class_name\": \"Dropout\",\n",
      "      \"config\": {\n",
      "        \"name\": \"dropout_3\",\n",
      "        \"trainable\": true,\n",
      "        \"rate\": 0.2,\n",
      "        \"noise_shape\": null,\n",
      "        \"seed\": null\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"class_name\": \"Dense\",\n",
      "      \"config\": {\n",
      "        \"name\": \"dense_2\",\n",
      "        \"trainable\": true,\n",
      "        \"units\": 2,\n",
      "        \"activation\": \"softmax\",\n",
      "        \"use_bias\": true,\n",
      "        \"kernel_initializer\": {\n",
      "          \"class_name\": \"VarianceScaling\",\n",
      "          \"config\": {\n",
      "            \"scale\": 1.0,\n",
      "            \"mode\": \"fan_avg\",\n",
      "            \"distribution\": \"uniform\",\n",
      "            \"seed\": null\n",
      "          }\n",
      "        },\n",
      "        \"bias_initializer\": {\n",
      "          \"class_name\": \"Zeros\",\n",
      "          \"config\": {}\n",
      "        },\n",
      "        \"kernel_regularizer\": null,\n",
      "        \"bias_regularizer\": null,\n",
      "        \"activity_regularizer\": null,\n",
      "        \"kernel_constraint\": null,\n",
      "        \"bias_constraint\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"keras_version\": \"2.1.1\",\n",
      "  \"backend\": \"tensorflow\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "to_publish = json.dumps(evaluation_metrics).encode('utf-8')\n",
    "print(json.dumps(evaluation_metrics, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kafka.producer.future.FutureRecordMetadata at 0x7f5555b207b8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# NOTE:\n",
    "# Setting this up with confluent's kafka library and cloud karafka was obnoxious. \n",
    "# This doesn't quite work:\n",
    "# sudo apt-get install libsasl2-dev librdkafka-dev\n",
    "# conda install -c conda-forge librdkafka\n",
    "# conda install -c conda-forge python-confluent-kafka\n",
    "\n",
    "\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "results_topic = \"test\"\n",
    "\n",
    "conf = {\n",
    "    'bootstrap.servers': [\"spark4.thedevranch.net\"],\n",
    "    'session.timeout.ms': 6000,\n",
    "    'default.topic.config': {'auto.offset.reset': 'smallest'},\n",
    "    #'security.protocol': 'sasl_ssl',#'SASL_SSL',\n",
    "    #'sasl.mechanisms': 'SCRAM-SHA-256',\n",
    "    #'sasl.username': \"p62g66c0\", #os.environ['CLOUDKARAFKA_USERNAME'],\n",
    "    #'sasl.password': \"mAbqsGu3L8_C8L_H31lktxnNfb1yAce5\", #os.environ['CLOUDKARAFKA_PASSWORD']\n",
    "}\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers=conf['bootstrap.servers'],\n",
    "#                          security_protocol=\"SASL_SSL\",\n",
    "#                          sasl_mechanism=\"PLAIN\",\n",
    "#                          sasl_plain_username=conf['sasl.username'],\n",
    "#                          sasl_plain_password=conf['sasl.password'],\n",
    "                        )\n",
    "\n",
    "def delivery_callback(err, msg):\n",
    "    if err:\n",
    "        sys.stderr.write('%% Message failed delivery: %s\\n' % err)\n",
    "    else:\n",
    "        sys.stderr.write('%% Message delivered to %s [%d]\\n' %\n",
    "                         (msg.topic(), msg.partition()))\n",
    "\n",
    "producer.send(\"test\", to_publish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
